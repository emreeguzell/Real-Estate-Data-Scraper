This project is a high-performance web scraping tool designed to extract real estate listings from Sahibinden.com and export them directly into a structured Excel file. It is built using Python, SeleniumBase, and Openpyxl.

ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Proje Ã–zeti
Bu araÃ§, Sahibinden.com Ã¼zerindeki emlak ilanlarÄ±nÄ± otomatik olarak Ã§ekmek ve bir Excel dosyasÄ±na kaydetmek iÃ§in geliÅŸtirilmiÅŸtir. SeleniumBase'in geliÅŸmiÅŸ "undetected" modunu kullanarak bot korumalarÄ±nÄ± aÅŸar ve verileri dÃ¼zenli bir tablo haline getirir.

âœ¨ Key Features (Ã–zellikler)

Anti-Bot Bypass: Uses SeleniumBase with undetected-mode to navigate through Cloudflare and other bot-detection systems.

Session Persistence: Supports user_data_dir to save browser cookies and sessions, minimizing the need for repetitive manual verification.

Smart Waiting: Implements advanced wait conditions to ensure elements are loaded before interaction.

OOP Design: Utilizes a clean Emlak class structure to handle and organize listing data efficiently.

Excel Integration: Automatically generates an .xlsx file with detailed headers (Listing Title, mÂ², Room Count, Price, Date, and Location).

ğŸ› ï¸ Requirements (Gereksinimler)

Python 3.x

SeleniumBase

Openpyxl

ğŸš€ Installation & Usage (Kurulum ve KullanÄ±m)

Clone the repository:

Bash
git clone https://github.com/yourusername/sahibindenscraping.git
cd sahibindenscraping
Install dependencies:

Bash
pip install seleniumbase openpyxl
Run the script:

Bash
python main.py
How it works:

The browser will launch and navigate to the site.

If a Cloudflare verification screen appears, solve it manually and press ENTER in the terminal.

Enter your search query (e.g., "KadÄ±kÃ¶y SatÄ±lÄ±k Daire") when prompted.

The results will be gathered and saved to Ä°lanlar.xlsx in the project folder.

ğŸ“‚ Project Structure (Proje YapÄ±sÄ±)
main.py: The core automation logic and data extraction.

âš ï¸ Disclaimer (Yasal UyarÄ±)
This project is intended for educational and personal use only. Scraping websites may violate their Terms of Service. The developer is not responsible for any misuse of this tool or potential legal consequences. Always respect the site's robots.txt and legal policies.
